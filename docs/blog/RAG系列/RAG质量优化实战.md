# RAGè´¨é‡ä¼˜åŒ–å®æˆ˜ï¼šä»è¯„ä¼°åˆ°ç”Ÿäº§ç¯å¢ƒçš„å®Œæ•´æŒ‡å—

## å¼€ç¯‡å¼•å…¥

åšäº†RAGç³»ç»Ÿï¼Œä½†ä¸çŸ¥é“è´¨é‡å¥½ä¸å¥½ï¼Ÿæ£€ç´¢æ€»æ˜¯ä¸å‡†ï¼Œå›ç­”æ€»æ˜¯å¹»è§‰ï¼Ÿä½ å¹¶ä¸å­¤å•ã€‚

RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿä¸Šçº¿å®¹æ˜“ï¼Œåšå¥½éš¾ã€‚å¾ˆå¤šå¼€å‘è€…ä¼šé‡åˆ°è¿™äº›ç—›ç‚¹ï¼š

- ä¸çŸ¥é“æ€ä¹ˆè¯„ä¼°RAGç³»ç»Ÿçš„è´¨é‡
- æ£€ç´¢å‡†ç¡®ç‡ä¸Šä¸å»ï¼Œå¬å›å¤ªä½ä¼šæœ‰å™ªå£°
- æ¨¡å‹ç»å¸¸"ä¸€æœ¬æ­£ç»åœ°èƒ¡è¯´å…«é“"
- ä¸Šä¸‹æ–‡çª—å£æœ‰é™ï¼Œä¸çŸ¥é“æ€ä¹ˆå–èˆ
- ä¼˜åŒ–æ•ˆæœæ²¡æœ‰æ•°æ®æ”¯æ’‘

æœ¬æ–‡å°†ç³»ç»Ÿæ€§åœ°ä»‹ç»RAGè´¨é‡ä¼˜åŒ–çš„å®Œæ•´æ–¹æ³•è®ºï¼Œä»è¯„ä¼°ä½“ç³»å»ºç«‹ï¼Œåˆ°æ£€ç´¢ä¼˜åŒ–ã€å¹»è§‰è§£å†³ï¼Œå†åˆ°A/Bæµ‹è¯•å’Œç”Ÿäº§ç›‘æ§ï¼Œç»™ä½ ä¸€å¥—å¯è½åœ°çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚

---

## ä¸€ã€RAGè´¨é‡è¯„ä¼°ä½“ç³»

### 1.1 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡

è¯„ä¼°RAGç³»ç»Ÿè´¨é‡ï¼Œéœ€è¦å…³æ³¨å››ä¸ªæ ¸å¿ƒæŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | å«ä¹‰ | è®¡ç®—æ–¹å¼ | ç›®æ ‡å€¼ |
|------|------|----------|--------|
| **å‡†ç¡®ç‡ (Precision)** | æ£€ç´¢çš„å†…å®¹æœ‰å¤šå°‘æ˜¯ç›¸å…³çš„ | TP / (TP + FP) | > 0.85 |
| **å¬å›ç‡ (Recall)** | ç›¸å…³å†…å®¹æœ‰å¤šå°‘è¢«æ£€ç´¢åˆ° | TP / (TP + FN) | > 0.80 |
| **F1åˆ†æ•°** | å‡†ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ | 2 Ã— P Ã— R / (P + R) | > 0.82 |
| **å»¶è¿Ÿ (Latency)** | å“åº”æ—¶é—´ | P50/P95/P99 | P99 < 2s |

å‡†ç¡®ç‡å’Œå¬å›ç‡å¾€å¾€éœ€è¦å¹³è¡¡ï¼šå¬å›å¤ªé«˜ä¼šæœ‰å™ªå£°å¹²æ‰°ï¼Œå‡†ç¡®å¤ªé«˜å¯èƒ½æ¼æ‰å…³é”®ä¿¡æ¯ã€‚

### 1.2 RAGASè¯„ä¼°æ¡†æ¶

**RAGAS** æ˜¯ä¸€ä¸ªå¼€æºçš„RAGè¯„ä¼°æ¡†æ¶ï¼Œå¯ä»¥è‡ªåŠ¨åŒ–è¯„ä¼°å…­ä¸ªç»´åº¦ï¼š

```python
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy, context_precision

# å‡†å¤‡æµ‹è¯•æ•°æ®
test_data = {
    "question": ["RAGæ˜¯ä»€ä¹ˆï¼Ÿ", "å¦‚ä½•ä¼˜åŒ–æ£€ç´¢å‡†ç¡®ç‡ï¼Ÿ"],
    "contexts": [["RAGæ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆ..."], ["ä¼˜åŒ–æ£€ç´¢å‡†ç¡®ç‡çš„æ–¹æ³•åŒ…æ‹¬..."]],
    "answer": ["RAGæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯", "ä¼˜åŒ–æ£€ç´¢å‡†ç¡®ç‡å¯ä»¥é€šè¿‡..."],
    "ground_truth": ["RAGæ˜¯Retrieval-Augmented Generation", "æ£€ç´¢å‡†ç¡®ç‡ä¼˜åŒ–åŒ…æ‹¬..."]
}

# è¿è¡Œè¯„ä¼°
result = evaluate(
    test_data,
    metrics=[faithfulness, answer_relevancy, context_precision]
)

print(result.to_dataframe())
```

**RAGASè¯„ä¼°ç»´åº¦ï¼š**

1. **å¿ å®åº¦ (Faithfulness)** - ç­”æ¡ˆæ˜¯å¦å®Œå…¨åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
2. **ç­”æ¡ˆç›¸å…³æ€§ (Answer Relevancy)** - ç­”æ¡ˆæ˜¯å¦ç›´æ¥å›ç­”äº†é—®é¢˜
3. **ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦ (Context Precision)** - ä¸Šä¸‹æ–‡æ˜¯å¦åŒ…å«ç­”æ¡ˆæ‰€éœ€ä¿¡æ¯
4. **ä¸Šä¸‹æ–‡å¬å›ç‡ (Context Recall)** - ä¸Šä¸‹æ–‡æ˜¯å¦å®Œæ•´è¦†ç›–é—®é¢˜

### 1.3 TruLensè¯„ä¼°å·¥å…·

**TruLens** æä¾›äº†ç«¯åˆ°ç«¯çš„RAGé“¾è·¯è¿½è¸ªå’Œå¯è§†åŒ–åˆ†æï¼š

```python
from trulens_eval import Tru, TruChain, Feedback

# åˆå§‹åŒ–TruLens
tru = Tru()

# åŒ…è£…RAGé“¾
tru_chain = TruChain(rag_chain)

# å®šä¹‰åé¦ˆæŒ‡æ ‡
f_relevance = Feedback(provider.relevance).on_input().on_output()

# è®°å½•å¹¶è¯„ä¼°
with tru_chain as recording:
    response = rag_chain.invoke("ä»€ä¹ˆæ˜¯RAGï¼Ÿ")

# å¯åŠ¨å¯è§†åŒ–ä»ªè¡¨ç›˜
tru.run_dashboard()
```

TruLensçš„ä¼˜åŠ¿åœ¨äºï¼š
- å®Œæ•´é“¾è·¯è¿½è¸ªï¼ˆæŸ¥è¯¢ â†’ æ£€ç´¢ â†’ ç”Ÿæˆï¼‰
- å¯è§†åŒ–ä»ªè¡¨ç›˜
- å¿«é€Ÿå®šä½æ€§èƒ½ç“¶é¢ˆ
- æ”¯æŒA/Bå¯¹æ¯”

### 1.4 å»ºç«‹è¯„ä¼°åŸºçº¿

å»ºè®®é‡‡ç”¨ **"è‡ªåŠ¨è¯„ä¼°ä¸ºä¸»ï¼Œäººå·¥è¯„ä¼°ä¸ºè¾…"** çš„ç­–ç•¥ï¼š

```python
# è¯„ä¼°åŸºçº¿é…ç½®
BASELINE_CONFIG = {
    "precision_threshold": 0.85,   # å‡†ç¡®ç‡åŸºçº¿
    "recall_threshold": 0.80,      # å¬å›ç‡åŸºçº¿
    "latency_p95_ms": 2000,        # P95å»¶è¿ŸåŸºçº¿
    "faithfulness_min": 0.75       # å¿ å®åº¦åŸºçº¿
}

def check_regression(current_metrics, baseline):
    """æ£€æŸ¥æ˜¯å¦å‘ç”Ÿæ€§èƒ½å›é€€"""
    for metric, threshold in baseline.items():
        if current_metrics[metric] < threshold:
            print(f"âš ï¸ {metric} å›é€€: {current_metrics[metric]} < {threshold}")
```

**ä½¿ç”¨å»ºè®®ï¼š**
- å»ºç«‹åŸºçº¿æ—¶ç”¨è‡ªåŠ¨è¯„ä¼°å¿«é€Ÿè¿­ä»£
- æ¯æœˆç”¨äººå·¥è¯„ä¼°æ ¡éªŒä¸€æ¬¡
- ä¿ç•™å†å²æ•°æ®è¿½è¸ªè¶‹åŠ¿

---

## äºŒã€æ£€ç´¢å‡†ç¡®ç‡æå‡

æ£€ç´¢è´¨é‡æ˜¯RAGçš„å‘½è„‰ã€‚æå‡å‡†ç¡®ç‡å¯ä»¥ä»å››ä¸ªç»´åº¦å…¥æ‰‹ã€‚

### 2.1 æŸ¥è¯¢ç†è§£ä¼˜åŒ–

ç”¨æˆ·çš„åŸå§‹æŸ¥è¯¢å¾€å¾€ä¸å¤Ÿç²¾ç¡®ï¼Œéœ€è¦è¿›è¡ŒæŸ¥è¯¢é‡å†™å’Œæ‰©å±•ï¼š

```python
def rewrite_query(original_query: str) -> str:
    """æŸ¥è¯¢é‡å†™ï¼šæŠŠéšå«æ„å›¾æ˜¾æ€§åŒ–"""
    prompt = f"""
    é‡å†™ä»¥ä¸‹æŸ¥è¯¢ï¼Œä½¿å…¶æ›´ç²¾ç¡®å®Œæ•´ï¼š
    åŸæŸ¥è¯¢: {original_query}

    è¦æ±‚:
    1. è¡¥å……éšå«çš„ä¸Šä¸‹æ–‡
    2. ä½¿ç”¨æ›´ä¸“ä¸šçš„æœ¯è¯­
    3. ä¿æŒç”¨æˆ·åŸæ„ä¸å˜
    """
    rewritten = llm.invoke(prompt)
    return rewritten

# ç¤ºä¾‹
rewrite_query("æ€ä¹ˆè°ƒä¼˜ï¼Ÿ")
# è¾“å‡º: "RAGç³»ç»Ÿå‚æ•°è°ƒä¼˜æ–¹æ³•"
```

**æŸ¥è¯¢æ‰©å±•** - ç”Ÿæˆå¤šä¸ªè¯­ä¹‰ç›¸å…³æŸ¥è¯¢ï¼š

```python
def expand_query(query: str, n_expansions: int = 3):
    """æŸ¥è¯¢æ‰©å±•ï¼šç”Ÿæˆå¤šä¸ªç›¸å…³æŸ¥è¯¢"""
    prompt = f"""
    ä¸ºä»¥ä¸‹æŸ¥è¯¢ç”Ÿæˆ{n_expansions}ä¸ªè¯­ä¹‰ç›¸å…³çš„æ‰©å±•æŸ¥è¯¢ï¼š
    åŸæŸ¥è¯¢: {query}
    """
    expansions = llm.invoke(prompt)
    return [query] + expansions

def multi_query_retrieval(query):
    """å¤šæŸ¥è¯¢æ£€ç´¢"""
    queries = expand_query(query)
    all_results = []
    for q in queries:
        results = vectorstore.similarity_search(q, k=3)
        all_results.extend(results)
    return deduplicate(all_results)
```

### 2.2 å‘é‡åµŒå…¥ä¼˜åŒ–

**æ¨¡å‹é€‰æ‹©å»ºè®®ï¼š**

| åœºæ™¯ | æ¨èæ¨¡å‹ | è¯´æ˜ |
|------|----------|------|
| é€šç”¨åœºæ™¯ | OpenAI text-embedding-3 | å…¼é¡¾å¤šè¯­è¨€ |
| ä¸­æ–‡åœºæ™¯ | M3E / BGE ç³»åˆ— | ä¸“é—¨ä¼˜åŒ–ä¸­æ–‡ |
| ç§æœ‰åŒ–éƒ¨ç½² | BAAI/bge-large-zh-v1.5 | å¼€æºå¯å•†ç”¨ |

**é¢†åŸŸå¾®è°ƒï¼š**

å¦‚æœä½ çš„é¢†åŸŸå¾ˆä¸“ä¸šï¼ˆå¦‚åŒ»ç–—ã€æ³•å¾‹ï¼‰ï¼Œå»ºè®®ç”¨é¢†åŸŸæ•°æ®å¾®è°ƒembeddingæ¨¡å‹ï¼Œæ•ˆæœèƒ½æå‡20%ä»¥ä¸Šã€‚

```python
from sentence_transformers import SentenceTransformer

# åŠ è½½ä¸­æ–‡embeddingæ¨¡å‹
model = SentenceTransformer("BAAI/bge-large-zh-v1.5")

# ç”Ÿæˆembedding
embeddings = model.encode(
    ["RAGæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯"],
    normalize_embeddings=True  # å½’ä¸€åŒ–æå‡ç›¸ä¼¼åº¦è®¡ç®—
)
```

### 2.3 ç´¢å¼•å‚æ•°è°ƒä¼˜

HNSWç´¢å¼•çš„å…³é”®å‚æ•°é…ç½®ï¼š

```python
import faiss

# åˆ›å»ºHNSWç´¢å¼•
index = faiss.IndexHNSWFlat(dimension, M=32)

# è®¾ç½®HNSWå‚æ•°
index.hnsw.efConstruction = 200  # æ„å»ºæ—¶å‚æ•°ï¼ˆå½±å“è´¨é‡ï¼‰
index.hnsw.efSearch = 150        # æœç´¢æ—¶å‚æ•°ï¼ˆå½±å“é€Ÿåº¦ï¼‰

# æ·»åŠ å‘é‡
index.add(vectors)

# æœç´¢
distances, indices = index.search(query_vector, k=10)
```

**å‚æ•°å»ºè®®ï¼š**

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|--------|------|
| M | 16-32 | æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§è¿æ¥æ•° |
| efConstruction | 200-400 | æ„å»ºæ—¶çš„è´¨é‡å‚æ•° |
| efSearch | efConstructionçš„50%-80% | æœç´¢æ—¶çš„æ¢ç´¢èŒƒå›´ |

**è°ƒä¼˜åŸåˆ™ï¼š** åœ¨ç²¾åº¦å’Œé€Ÿåº¦ä¹‹é—´æ‰¾å¹³è¡¡ã€‚å¯ä»¥å…ˆè®¾ç½®è¾ƒé«˜çš„efSearchï¼Œè§‚å¯ŸP95å»¶è¿Ÿï¼Œå†é€æ­¥é™ä½ã€‚

### 2.4 å…ƒæ•°æ®è¿‡æ»¤

ç»“åˆæ–‡æ¡£å…ƒä¿¡æ¯è¿›è¡Œè¿‡æ»¤ï¼Œæå‡æ£€ç´¢ç²¾ç¡®åº¦ï¼š

```python
from datetime import datetime, timedelta

def search_with_filter(query, months_ago=6):
    """å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢"""
    cutoff_date = datetime.now() - timedelta(days=months_ago*30)

    results = vectorstore.similarity_search(
        query,
        k=5,
        filter={
            "publication_date": {"$gte": cutoff_date},
            "source": {"$in": ["arxiv", "nature"]}
        }
    )
    return results

# ç¤ºä¾‹ï¼šæŸ¥æ‰¾æœ€æ–°çš„RAGä¼˜åŒ–æ–¹æ³•
results = search_with_filter("RAG optimization", months_ago=6)
```

**å…ƒæ•°æ®è¿‡æ»¤ç»´åº¦ï¼š**
- æ—¶é—´è¿‡æ»¤ï¼ˆåªæ£€ç´¢æœ€è¿‘Nä¸ªæœˆçš„æ–‡æ¡£ï¼‰
- æ¥æºè¿‡æ»¤ï¼ˆåªæ£€ç´¢æƒå¨æ¥æºï¼‰
- ç±»åˆ«è¿‡æ»¤ï¼ˆé™å®šç‰¹å®šæ–‡æ¡£ç±»åˆ«ï¼‰
- ç»„åˆè¿‡æ»¤ï¼ˆå¤šæ¡ä»¶ç»„åˆæŸ¥è¯¢ï¼‰

---

## ä¸‰ã€å¹»è§‰é—®é¢˜è§£å†³

å¹»è§‰æ˜¯RAGæœ€å¤´ç–¼çš„é—®é¢˜ã€‚æ¨¡å‹æ˜æ˜æ£€ç´¢åˆ°äº†å†…å®¹ï¼Œå´ä¸€æœ¬æ­£ç»åœ°èƒ¡è¯´å…«é“ã€‚

### 3.1 å¹»è§‰æ ¹æºåˆ†æ

| æ ¹æº | è¡¨ç° | è§£å†³æ–¹å‘ |
|------|------|----------|
| æ£€ç´¢å†…å®¹ä¸å¤Ÿç›¸å…³ | ä¸Šä¸‹æ–‡ä¸æŸ¥è¯¢åç¦» | æé«˜ç›¸å…³æ€§é˜ˆå€¼ |
| ä¸Šä¸‹æ–‡å™ªå£°å¤ªå¤š | å¹²æ‰°ä¿¡æ¯å½±å“åˆ¤æ–­ | å‡å°‘æ£€ç´¢æ•°é‡ã€é‡æ’åº |
| æ¨¡å‹å€¾å‘è‡†é€  | LLMçš„è®­ç»ƒç‰¹æ€§ | ç­”æ¡ˆéªŒè¯ã€æ‹’ç»å›ç­” |

### 3.2 æ£€ç´¢å¢å¼ºç­–ç•¥

ä»æºå¤´æå‡æ£€ç´¢è´¨é‡ï¼š

```python
def retrieve_with_threshold(query, threshold=0.7):
    """ç›¸å…³æ€§é˜ˆå€¼è¿‡æ»¤"""
    # æ£€ç´¢æ›´å¤šå€™é€‰
    candidates = vectorstore.similarity_search_with_score(query, k=20)

    # ç›¸å…³æ€§è¿‡æ»¤
    filtered = [(doc, score) for doc, score in candidates
                if score >= threshold]

    if not filtered:
        return None  # æ— ç›¸å…³ç»“æœï¼Œæ‹’ç»å›ç­”

    # é‡æ’åº
    reranked = rerank(query, filtered)
    return reranked[:5]
```

**ç­–ç•¥è¦ç‚¹ï¼š**
- æé«˜ç›¸å…³æ€§é˜ˆå€¼ï¼Œåªä½¿ç”¨é«˜è´¨é‡æ£€ç´¢ç»“æœ
- åŠ¨æ€è°ƒæ•´kå€¼ï¼Œæ ¹æ®ç›¸å…³æ€§åˆ†æ•°å†³å®šæ£€ç´¢æ•°é‡
- ç”¨Cross-Encoderå¯¹ç»“æœé‡æ–°æ’åº
- æ— ç›¸å…³ç»“æœæ—¶æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·

### 3.3 ç­”æ¡ˆéªŒè¯æœºåˆ¶

ç”Ÿæˆç­”æ¡ˆåï¼ŒéªŒè¯å…¶æ˜¯å¦åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼š

```python
def verify_answer(answer, context):
    """ç­”æ¡ˆéªŒè¯"""
    prompt = f"""
    æ£€æŸ¥ä»¥ä¸‹ç­”æ¡ˆæ˜¯å¦å®Œå…¨åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ï¼š

    ä¸Šä¸‹æ–‡: {context}
    ç­”æ¡ˆ: {answer}

    è¯·æ£€æŸ¥:
    1. ç­”æ¡ˆä¸­çš„äº‹å®æ˜¯å¦éƒ½åœ¨ä¸Šä¸‹æ–‡ä¸­
    2. æ¨ç†æ˜¯å¦åˆç†
    3. æ˜¯å¦æ·»åŠ äº†é¢å¤–ä¿¡æ¯

    è¿”å›: é€šè¿‡/ä¸é€šè¿‡ + åŸå› 
    """
    verification = llm.invoke(prompt)
    return verification
```

### 3.4 ä¸ç¡®å®šæ€§å¤„ç†

è®­ç»ƒæ¨¡å‹åœ¨ä¸ç¡®å®šæ—¶è¯´"ä¸çŸ¥é“"ï¼š

```python
def generate_with_confidence(query, context):
    """å¸¦ç½®ä¿¡åº¦çš„ç”Ÿæˆ"""
    prompt = f"""
    åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œå¹¶ç»™å‡ºç½®ä¿¡åº¦(0-1)ï¼š
    ä¸Šä¸‹æ–‡: {context}
    é—®é¢˜: {query}
    æ ¼å¼: ç­”æ¡ˆ [ç½®ä¿¡åº¦: X.XX]
    """
    response = llm.invoke(prompt)
    confidence = extract_confidence(response)

    if confidence < 0.6:
        return "æŠ±æ­‰ï¼ŒåŸºäºç°æœ‰ä¿¡æ¯æˆ‘æ— æ³•ç¡®å®šç­”æ¡ˆã€‚"
    return response
```

### 3.5 å¼•ç”¨æº¯æºè®¾è®¡

è®©ç­”æ¡ˆä¸­çš„æ¯ä¸ªé™ˆè¿°éƒ½æ ‡æ³¨æ¥æºï¼š

```python
prompt = """
å›ç­”é—®é¢˜æ—¶ï¼Œè¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. åªåŸºäºæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”
2. æ¯ä¸ªé™ˆè¿°åæ·»åŠ å¼•ç”¨æ ‡æ³¨ [citation:N]
3. Næ˜¯ä¸Šä¸‹æ–‡æ–‡æ¡£çš„ç¼–å·
4. ä¸è¦æ·»åŠ ä¸Šä¸‹æ–‡å¤–çš„ä¿¡æ¯

ä¸Šä¸‹æ–‡:
{contexts}

é—®é¢˜: {question}
"""
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
> RAGï¼ˆRetrieval-Augmented Generationï¼‰æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„AIæ¶æ„[citation:1]ã€‚å®ƒé€šè¿‡å¤–éƒ¨çŸ¥è¯†åº“å¢å¼ºLLMçš„èƒ½åŠ›[citation:2]ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘å¹»è§‰é—®é¢˜[citation:3]ã€‚

---

## å››ã€ä¸Šä¸‹æ–‡çª—å£ç®¡ç†

æ¨¡å‹èƒ½å¤„ç†çš„å†…å®¹é•¿åº¦æœ‰é™ï¼Œå¦‚ä½•é«˜æ•ˆåˆ©ç”¨ä¸Šä¸‹æ–‡çª—å£ï¼Ÿ

### 4.1 å†…å®¹å‹ç¼©ç­–ç•¥

æ™ºèƒ½å‹ç¼©æ£€ç´¢ç»“æœï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼š

```python
def compress_context(documents, query, max_tokens=2000):
    """ä¸Šä¸‹æ–‡å‹ç¼©"""
    # æŒ‰é‡è¦æ€§æ’åº
    scored_docs = [(doc, calculate_relevance(doc, query))
                   for doc in documents]
    scored_docs.sort(key=lambda x: x[1], reverse=True)

    # é€æ­¥æ·»åŠ ç›´åˆ°è¾¾åˆ°é™åˆ¶
    selected = []
    current_tokens = 0
    for doc, score in scored_docs:
        doc_tokens = estimate_tokens(doc)
        if current_tokens + doc_tokens > max_tokens:
            break
        selected.append(doc)
        current_tokens += doc_tokens

    return selected
```

### 4.2 åˆ†å—å¤„ç†æŠ€å·§

**è¯­ä¹‰åˆ‡åˆ†** - åœ¨è¯­ä¹‰è¾¹ç•Œå¤„åˆ‡åˆ†ï¼š

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# è¯­ä¹‰æ„ŸçŸ¥çš„æ–‡æœ¬åˆ‡åˆ†
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100,  # 20%é‡å 
    separators=["\n\n", "\n", "ã€‚", ".", " ", ""]
)

chunks = splitter.split_text(document)
```

**æ»‘åŠ¨çª—å£+é‡å **ç­–ç•¥ç¡®ä¿è¾¹ç•Œä¿¡æ¯ä¸ä¸¢å¤±ï¼š
- æ¯ä¸ªchunkå’Œç›¸é‚»chunkæœ‰20%çš„é‡å 
- åœ¨æ®µè½ã€ç« èŠ‚è¾¹ç•Œåˆ‡åˆ†
- ä¿æŒè¯­ä¹‰è¿è´¯æ€§

### 4.3 ä¼˜å…ˆçº§æ’åº

å»ºç«‹è¯„åˆ†æœºåˆ¶ï¼Œåªæ”¾å…¥æœ€ç›¸å…³çš„å†…å®¹ï¼š

```python
def calculate_priority_score(doc, query):
    """è®¡ç®—ä¼˜å…ˆçº§åˆ†æ•°"""
    score = 0

    # è¯­ä¹‰ç›¸ä¼¼åº¦ (40%)
    score += doc['similarity'] * 0.4

    # æ–‡æ¡£æ—¶æ•ˆæ€§ (20%)
    recency_score = calculate_recency(doc['date'])
    score += recency_score * 0.2

    # æ¥æºæƒå¨æ€§ (20%)
    authority_score = AUTHORITY_SCORES.get(doc['source'], 0.5)
    score += authority_score * 0.2

    # å†…å®¹å®Œæ•´æ€§ (20%)
    score += doc.get('completeness', 0.5) * 0.2

    return score
```

---

## äº”ã€A/Bæµ‹è¯•æ¡†æ¶

ä¼˜åŒ–ä¸èƒ½å‡­æ„Ÿè§‰ï¼Œè¦ç”¨æ•°æ®è¯´è¯ã€‚

### 5.1 A/Bæµ‹è¯•è®¾è®¡

| å¯¹ç…§ç»„ | å®éªŒç»„ |
|--------|--------|
| å½“å‰çº¿ä¸Šé…ç½® | ä¼˜åŒ–åçš„é…ç½® |
| ç°æœ‰embeddingæ¨¡å‹ | æ–°çš„embeddingæ¨¡å‹ |
| ç°æœ‰æ£€ç´¢å‚æ•° | è°ƒä¼˜åçš„æ£€ç´¢å‚æ•° |

### 5.2 æµé‡åˆ†é…ç­–ç•¥

```python
import hashlib

def get_ab_group(user_id, experiment_name, traffic_ratio=0.05):
    """ç¨³å®šçš„A/Båˆ†æµ"""
    hash_value = int(hashlib.md5(
        f"{experiment_name}:{user_id}".encode()
    ).hexdigest(), 16)

    if hash_value % 100 < traffic_ratio * 100:
        return "experiment"
    else:
        return "control"

# ä½¿ç”¨
group = get_ab_group(user.id, "rag_v2")
if group == "experiment":
    response = rag_v2.query(query)
else:
    response = rag_v1.query(query)
```

**æµé‡åˆ†é…å»ºè®®ï¼š**
- å°æµé‡èµ·æ­¥ï¼ˆ5%ï¼‰
- æ— å›å½’åé€æ­¥æ”¾å¤§ï¼ˆ20% â†’ 50% â†’ 100%ï¼‰
- ç¡®ä¿ç”¨æˆ·éšæœºä¸”ç¨³å®šåœ°åˆ†é…åˆ°ä¸¤ç»„

### 5.3 å…³é”®æŒ‡æ ‡ç›‘æ§

| æŒ‡æ ‡ç±»å‹ | å…·ä½“æŒ‡æ ‡ | ç›‘æ§æ–¹å¼ |
|----------|----------|----------|
| ç”¨æˆ·æ»¡æ„åº¦ | ç‚¹èµç‡ã€è´Ÿé¢åé¦ˆç‡ | ç”¨æˆ·è¡Œä¸ºç»Ÿè®¡ |
| ç­”æ¡ˆç›¸å…³æ€§ | RAGASè‡ªåŠ¨è¯„ä¼° | å®šæœŸè¯„ä¼° |
| å“åº”å»¶è¿Ÿ | P50/P95/P99 | APMç›‘æ§ |
| æˆæœ¬ | Tokenæ¶ˆè€—ã€APIè°ƒç”¨é‡ | è´¦å•ç»Ÿè®¡ |

### 5.4 ç»“æœåˆ†æ

æµ‹è¯•è‡³å°‘è¿è¡Œ1-2å‘¨ï¼Œè¦†ç›–ä¸åŒæ—¶é—´æ®µå’Œç”¨æˆ·ç¾¤ä½“ã€‚

**åˆ†æè¦ç‚¹ï¼š**
- ä½¿ç”¨ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆtæ£€éªŒæˆ–å¡æ–¹æ£€éªŒï¼‰
- å…³æ³¨åˆ†ä½æ•°æ•°æ®ï¼ˆP95/P99ï¼‰è€Œéä»…å¹³å‡å€¼
- æŒ‰ç”¨æˆ·ç±»å‹ã€æŸ¥è¯¢ç±»å‹ç»†åˆ†åˆ†æ
- é¿å…æ–°å¥‡æ•ˆåº”å¹²æ‰°

---

## å…­ã€ç”Ÿäº§ç¯å¢ƒç›‘æ§

ä¼˜åŒ–ä¸æ˜¯ä¸€æ¬¡æ€§çš„ï¼Œè€Œæ˜¯è¦æŒç»­ç›‘æ§ã€‚

### 6.1 ç›‘æ§æŒ‡æ ‡ä½“ç³»

| æŒ‡æ ‡ç±»å‹ | å…·ä½“æŒ‡æ ‡ | å‘Šè­¦é˜ˆå€¼ |
|----------|----------|----------|
| è´¨é‡æŒ‡æ ‡ | å‡†ç¡®ç‡ã€å¹»è§‰ç‡ | å‡†ç¡®ç‡ < åŸºçº¿Ã—90% |
| æ€§èƒ½æŒ‡æ ‡ | P50/P95/P99å»¶è¿Ÿ | P99 > 3s |
| ä¸šåŠ¡æŒ‡æ ‡ | DAUã€æŸ¥è¯¢é‡ã€ç•™å­˜ | - |
| æˆæœ¬æŒ‡æ ‡ | Tokenæ¶ˆè€—ã€APIè°ƒç”¨é‡ | æ—¥æ¶ˆè€—è¶…é¢„ç®— |

### 6.2 æ—¥å¿—åˆ†æ

è®°å½•æ¯ä¸ªè¯·æ±‚çš„å®Œæ•´é“¾è·¯ï¼š

```python
def log_rag_request(request_id, query, context, response):
    """æ—¥å¿—è®°å½•"""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "request_id": request_id,
        "query": query,
        "retrieved_docs": [{"id": d.id, "score": d.score} for d in context],
        "prompt_tokens": count_tokens(context),
        "response": response,
        "latency_ms": measure_latency(),
        "user_feedback": None  # ç¨åæ›´æ–°
    }
    logger.info(f"RAG_REQUEST: {json.dumps(log_entry)}")
```

### 6.3 è‡ªåŠ¨å‘Šè­¦

```python
ALERT_RULES = {
    "accuracy_drop": {
        "condition": lambda m: m['accuracy'] < BASELINE['accuracy'] * 0.9,
        "severity": "high",
        "message": "å‡†ç¡®ç‡ä¸‹é™è¶…è¿‡10%!"
    },
    "high_latency": {
        "condition": lambda m: m['p99_latency'] > 3000,
        "severity": "medium",
        "message": "P99å»¶è¿Ÿè¶…è¿‡3ç§’"
    }
}

def check_alerts(metrics):
    """æ£€æŸ¥å‘Šè­¦"""
    for rule_name, rule in ALERT_RULES.items():
        if rule['condition'](metrics):
            send_alert(rule['message'], rule['severity'])
```

### 6.4 æŒç»­ä¼˜åŒ–æµç¨‹

å»ºç«‹ä¼˜åŒ–çš„é—­ç¯æœºåˆ¶ï¼š

```
æ¯æ—¥ç›‘æ§ â†’ æ¯å‘¨Review â†’ æ¯æœˆæ·±åº¦åˆ†æ â†’ æ¯å­£åº¦æ¶æ„ä¼˜åŒ–
```

---

## æ€»ç»“

RAGè´¨é‡ä¼˜åŒ–æ˜¯ä¸€ä¸ªç³»ç»Ÿå·¥ç¨‹ï¼Œéœ€è¦ä»è¯„ä¼°ã€æ£€ç´¢ã€å¹»è§‰ã€ä¸Šä¸‹æ–‡ã€æµ‹è¯•ã€ç›‘æ§å…­ä¸ªç»´åº¦ç»¼åˆè€ƒè™‘ï¼š

1. **å»ºç«‹è¯„ä¼°ä½“ç³»** - ç”¨RAGASå’ŒTruLenså·¥å…·è‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œå®šæœŸäººå·¥æ ¡éªŒ
2. **ä¼˜åŒ–æ£€ç´¢è´¨é‡** - æŸ¥è¯¢ç†è§£ã€å‘é‡ä¼˜åŒ–ã€ç´¢å¼•è°ƒä¼˜ã€å…ƒæ•°æ®è¿‡æ»¤å››ç®¡é½ä¸‹
3. **è§£å†³å¹»è§‰é—®é¢˜** - æ£€ç´¢å¢å¼ºã€ç­”æ¡ˆéªŒè¯ã€ä¸ç¡®å®šæ€§å¤„ç†ã€å¼•ç”¨æº¯æº
4. **ç®¡ç†ä¸Šä¸‹æ–‡çª—å£** - å†…å®¹å‹ç¼©ã€åˆ†å—æŠ€å·§ã€ä¼˜å…ˆçº§æ’åº
5. **A/Bæµ‹è¯•éªŒè¯** - ç”¨ç§‘å­¦æ–¹æ³•éªŒè¯ä¼˜åŒ–æ•ˆæœ
6. **ç”Ÿäº§ç¯å¢ƒç›‘æ§** - æŒç»­ç›‘æ§å’Œè¿­ä»£ä¼˜åŒ–

RAGç³»ç»Ÿä¼˜åŒ–æ˜¯ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œæ²¡æœ‰ç»ˆç‚¹ã€‚ä½†æŒæ¡è¿™å¥—æ–¹æ³•è®ºï¼Œä½ å°±æœ‰äº†æ¸…æ™°çš„è·¯çº¿å›¾ã€‚

---

## é…å¥—èµ„æº

**å¯è§†åŒ–æ¼”ç¤ºï¼š**
- é…å¥—HTMLå¯è§†åŒ–æ¼”ç¤ºç½‘é¡µï¼ˆåœ¨è§†é¢‘ä¸­å±•ç¤ºï¼‰

**è§†é¢‘æ•™ç¨‹ï¼š**
å·²åœ¨åŒåè´¦å·å‘å¸ƒåˆ°ä»¥ä¸‹å¹³å°
- ğŸ“º æŠ–éŸ³ï¼šæœç´¢"æ¶æ„ç‹®ä¸æ©˜"
- ğŸ“º å¿«æ‰‹ï¼šæœç´¢"æ¶æ„ç‹®ä¸æ©˜"
- ğŸ“º å“”å“©å“”å“©ï¼šæœç´¢"æ¶æ„ç‹®ä¸æ©˜"

---

> æœ¬æ–‡ä½œè€…ï¼šæ¶æ„ç‹®ä¸æ©˜
> å‘å¸ƒæ—¶é—´ï¼š2026å¹´1æœˆ
> æŠ€æœ¯æ ˆï¼šRAG / LLM / Python / LangChain
